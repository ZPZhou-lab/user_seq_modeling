from transformers import AutoModelForCausalLM, AutoConfig
from transformers.models.llama.modeling_llama import LlamaModel, LlamaForCausalLM
import torch
from torch import nn
import torch.nn.functional as F


class UserEncoder(nn.Module):
    def __init__(self,
        model_path: str,
    ):
        super(UserEncoder, self).__init__()
        # load pretrained llm
        llm = AutoModelForCausalLM.from_pretrained(
            model_path, 
            torch_dtype='auto',
            device_map="auto",
            trust_remote_code=True
        )
        # remove embedding layer and only keep the encoder
        self.llm = llm.base_model
    
    def forward(self, 
        event_embeddings: torch.Tensor, 
        attention_mask: torch.Tensor
    ) -> torch.Tensor:
        """
        encode user inputs into hidden_states
        """
        # get embedding
        outputs = self.llm(
            inputs_embeds=event_embeddings,
            attention_mask=attention_mask.to(self.llm.device),
            use_cache=False,
            output_hidden_states=False,
            output_attentions=False
        )
        # extract the last hidden state with shape (batch, seq_len, hidden_size)
        return outputs.last_hidden_state
    

class GenerativeInfoNCELoss(nn.Module):
    def __init__(self, temperature=0.1, neg_samples=10):
        super().__init__()
        self.temperature = nn.Parameter(torch.tensor(temperature))
        self.neg_samples = neg_samples
        
    def forward(self, 
        encoder_outputs: torch.Tensor,
        event_embeddings: torch.Tensor
    ):
        """
        Parameters
        ----------
        encoder_outputs: (batch, seq_len, hidden)
            The encoder outputs generated by the UserEncoder, are the next-event embeddings predictions
        event_embeddings: (batch, seq_len, hidden)
            The event embeddings generated by the EventEncoder, are the inputs of UserEncoder
        """
        batch_size, seq_len, hidden_dim = encoder_outputs.shape
        
        # postive samples
        positives = event_embeddings[:, 1:, :]  # (batch, seq_len-1, hidden)
        predictions = encoder_outputs[:, :-1, :]  # (batch, seq_len-1, hidden)
        
        # randomly sample negative samples within the batch from the other event sequences
        # with shape (batch, seq_len-1, neg_samples, hidden)
        negatives = self._negative_sampling(event_embeddings)  
        
        # calculate the similarity scores
        pos_scores = F.cosine_similarity(predictions, positives, dim=-1) / self.temperature  # (batch, seq_len-1)
        neg_scores = torch.einsum('bsh,bsnh->bsn', predictions, negatives) / self.temperature  # (batch, seq_len-1, neg_samples)
        
        # combine positive and negative scores (batch, seq_len-1, neg_samples+1)
        logits = torch.cat([pos_scores.unsqueeze(-1), neg_scores], dim=-1)
        
        # calculate the info NCE loss
        labels = torch.zeros(batch_size, seq_len-1, dtype=torch.long, device=encoder_outputs.device)
        loss = F.cross_entropy(logits.view(-1, self.neg_samples + 1), labels.view(-1))
        
        return loss
    
    def _negative_sampling(self, event_embeddings: torch.Tensor):
        """
        sample negative samples from the event embeddings
        """
        device = event_embeddings.device
        batch_size, seq_len, hidden_dim = event_embeddings.shape

        # flatten into (batch * seq_len, hidden_dim)
        event_embeddings = event_embeddings.view(-1, hidden_dim)

        event_indices = torch.arange(batch_size * seq_len, device=device)
        neg_indices = []
        mask_offset = 0
        for b in range(batch_size):
            # create mask for the current batch
            mask = torch.where((event_indices - mask_offset) // seq_len)[0]
            random_indices = torch.randperm(len(mask) * (seq_len - 1)) % len(mask)
            random_indices = random_indices[:self.neg_samples * (seq_len - 1)]
            neg_indices.append(mask[random_indices])
            mask_offset += seq_len
        # stack negative indices and gather negative samples
        neg_indices = torch.concat(neg_indices, dim=0)
        negatives = event_embeddings[neg_indices]
        # reshape negatives to (batch, seq_len-1, neg_samples, hidden_dim)
        negatives = negatives.view(batch_size, seq_len-1, self.neg_samples, hidden_dim)
        
        return negatives